{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heil/llama-all-local/.env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "MODELNAME = \"TheBloke/OpenHermes-2.5-Mistral-7B-GGUF\"\n",
    "FILENAME = \"openhermes-2.5-mistral-7b.Q4_K_M.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 4301.85it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 4396.55it/s]\n"
     ]
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained(\"teknium/OpenHermes-2.5-Mistral-7B\")\n",
    "mod = AutoModelForCausalLM.from_pretrained(\n",
    "    MODELNAME, \n",
    "    model_file = FILENAME,\n",
    "    model_type = \"mistral\",\n",
    "    gpu_layers = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<|im_start|>system\n",
      "You want to give detailed summaries of information<|im_end|>\n",
      "<|im_start|>user\n",
      "- molecules are made of atoms\n",
      "\n",
      "- ions are charged particles<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"\"\"\n",
    "<|im_start|>system\n",
    "You want to give detailed summaries of information<|im_end|>\n",
    "<|im_start|>user\n",
    "- molecules are made of atoms\\n\n",
    "- ions are charged particles<|im_end|>\n",
    "\"\"\"\n",
    "\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' that enables a chatbot to provide answers and generate follow-up prompts\\n\\nIn order for a chatbot to effectively engage with users, it needs to be able to understand the user\\'s input and respond appropriately. One way to achieve this is through the use of ChatML, which stands for \"chat markup language\". This prompting language enables a chatbot to provide answers and generate follow-up prompts based on the user\\'s input.\\n\\nChatML is essentially a set of predefined commands or syntax rules that are used by a chatbot to understand and respond to user queries. These commands can be used to extract information from the user, such as their name, age, or location, and can also be used to provide answers to questions or offer suggestions based on the user\\'s input.\\n\\nFor example, a simple ChatML command might look like this:\\n\\nUser: What is your name?\\nChatbot: My name is [name]. How may I assist you today?\\n\\nIn this case, the chatbot is using ChatML to extract the user\\'s name and then provide a response that includes a follow-up prompt asking how it can help. This type of interaction allows for a more natural and'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(\"explain ChatML prompting language\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
